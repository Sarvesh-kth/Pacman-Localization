{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing particle filter for pacman tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattanweights(g1, g2, g3, g4, pc):\n",
    "    w1 = 1 / (abs(g1[0] - pc[0]) + abs(g1[1] - pc[1]) + 1e-7)\n",
    "    w2 = 1 / (abs(g2[0] - pc[0]) + abs(g2[1] - pc[1]) + 1e-7)\n",
    "    w3 = 1 / (abs(g3[0] - pc[0]) + abs(g3[1] - pc[1]) + 1e-7)\n",
    "    w4 = 1 / (abs(g4[0] - pc[0]) + abs(g4[1] - pc[1]) + 1e-7)\n",
    "    return [w1, w2, w3, w4]\n",
    "\n",
    "def motion_model_ghosts(g,pc,allow_motion):\n",
    "    ad = au = ar = al = 1\n",
    "    if g[0] > pc[0]:\n",
    "        al += (g[0] - pc[0])\n",
    "    elif g[0] < pc[0]:\n",
    "        ar += (pc[0] - g[0])\n",
    "    if g[1] > pc[1]:\n",
    "        au += (g[1] - pc[1])\n",
    "    elif g[1] < pc[1]:\n",
    "        ad += (pc[1] - g[1])  \n",
    "\n",
    "\n",
    "    # normalize probabilities\n",
    "    sum = al + ad + au + ar\n",
    "    p_l = al/sum\n",
    "    p_r = ar/sum\n",
    "    p_u = au/sum\n",
    "    p_d = ad/sum\n",
    "\n",
    "    # Given Dictionary of allowable motions, if cannot move direction, split the probabilities to other directions\n",
    "    if allow_motion['u'] == 0:\n",
    "        p_r += 0.4*p_u\n",
    "        p_l += 0.4*p_u\n",
    "        p_d += 0.2*p_u\n",
    "        p_u = 0\n",
    "    \n",
    "    if allow_motion['d'] == 0:\n",
    "        p_r += 0.4*p_d\n",
    "        p_l += 0.4*p_d\n",
    "        p_u += 0.2*p_u\n",
    "        p_d = 0\n",
    "    \n",
    "    if allow_motion['r'] == 0:\n",
    "        p_u += 0.4*p_r\n",
    "        p_d += 0.4*p_r\n",
    "        p_l += 0.2*p_r\n",
    "        p_r = 0\n",
    "    \n",
    "    if allow_motion['l'] == 0:\n",
    "        p_u += 0.4*p_l\n",
    "        p_d += 0.4*p_l\n",
    "        p_r += 0.2*p_l\n",
    "        p_l = 0\n",
    "\n",
    "    return p_l,p_r,p_u,p_d\n",
    "\n",
    "def motion_model(g1, g2, g3, g4, pc, prev_action, allow_motion):\n",
    "    ad = ar = al = au = 1\n",
    "    wl = manhattanweights(g1, g2, g3, g4, pc)\n",
    "    gl = [g1, g2, g3, g4]\n",
    "    # weighted sum of ghosts position in each direction\n",
    "    # higher sum, indicates ghosts closer to pacman in respective direction\n",
    "    for g, w in zip(gl, wl):\n",
    "        if g[0] > pc[0]:\n",
    "            al += w / (g[0] - pc[0] + 1e-7)\n",
    "        elif g[0] < pc[0]:\n",
    "            ar += w / (pc[0] - g[0] + 1e-7)\n",
    "        if g[1] > pc[1]:\n",
    "            au += w / (g[1] - pc[1] + 1e-7)\n",
    "        elif g[1] < pc[1]:\n",
    "            ad += w / (pc[1] - g[1] + 1e-7)\n",
    "\n",
    "    # Inverse to obtain higher values indicate more probable direction of motion\n",
    "    ad = 1 / ad\n",
    "    au = 1 / au\n",
    "    ar = 1 / ar\n",
    "    al = 1 / al\n",
    "\n",
    "    # Likely to repeat action, so scale up probability\n",
    "    if prev_action == \"r\":\n",
    "        ar = ar * 1.25\n",
    "    elif prev_action == \"l\":\n",
    "        al = al * 1.25\n",
    "    elif prev_action == \"u\":\n",
    "        au = au * 1.25\n",
    "    elif prev_action == \"d\":\n",
    "        ad = ad * 1.25\n",
    "\n",
    "    # normalize probabilities\n",
    "    sum = al + ad + au + ar\n",
    "    p_l = al / sum\n",
    "    p_r = ar / sum\n",
    "    p_u = au / sum\n",
    "    p_d = ad / sum\n",
    "\n",
    "    # Given Dictionary of allowable motions, if cannot move direction, split the probabilities to other directions\n",
    "    if allow_motion[\"u\"] == 0:\n",
    "        p_r += 0.4 * p_u\n",
    "        p_l += 0.4 * p_u\n",
    "        p_d += 0.2 * p_u\n",
    "        p_u = 0\n",
    "\n",
    "    if allow_motion[\"d\"] == 0:\n",
    "        p_r += 0.4 * p_d\n",
    "        p_l += 0.4 * p_d\n",
    "        p_u += 0.2 * p_u\n",
    "        p_d = 0\n",
    "\n",
    "    if allow_motion[\"r\"] == 0:\n",
    "        p_u += 0.4 * p_r\n",
    "        p_d += 0.4 * p_r\n",
    "        p_l += 0.2 * p_r\n",
    "        p_r = 0\n",
    "\n",
    "    if allow_motion[\"l\"] == 0:\n",
    "        p_u += 0.4 * p_l\n",
    "        p_d += 0.4 * p_l\n",
    "        p_r += 0.2 * p_l\n",
    "        p_l = 0\n",
    "\n",
    "    return p_l, p_r, p_u, p_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extract:\n",
    "    \"\"\"\n",
    "    Extracts all relevant information from the current frame\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.object_colors = {\n",
    "            \"pacman\": {\"lower\": (25, 100, 100), \"upper\": (35, 255, 255)},  # Yellow\n",
    "            \"red_ghost\": [\n",
    "        {\"lower\": (0, 100, 100), \"upper\": (5, 255, 255)},   # Red range 1\n",
    "        {\"lower\": (160, 100, 100), \"upper\": (180, 255, 255)}  # Red range 2\n",
    "    ],  # Red\n",
    "            \"cyan_ghost\": {\"lower\": (80, 100, 100), \"upper\": (100, 255, 255)},  # Cyan\n",
    "            \"pink_ghost\": {\"lower\": (110, 20, 50), \"upper\": (160, 110, 255)},  # Pink\n",
    "            \"orange_ghost\": {\"lower\": (5, 20, 100), \"upper\": (20, 255, 255)},  # Orange\n",
    "        }\n",
    "        self.ghost_marker_colors = {\n",
    "            \"pacman\": (0, 255, 255),\n",
    "            \"red_ghost\": (0, 0, 255),\n",
    "            \"cyan_ghost\": (255, 255, 0),\n",
    "            \"pink_ghost\": (255, 0, 255),\n",
    "            \"orange_ghost\": (0, 100, 255),\n",
    "        }\n",
    "        self.movements = {\n",
    "            1: \"up\",\n",
    "            -1: \"down\",\n",
    "            -10: \"left\",\n",
    "            10: \"right\",\n",
    "            11: \"upright\",\n",
    "            -11: \"downleft\",\n",
    "            9: \"upleft\",\n",
    "            -9: \"downright\",\n",
    "            0: \"nomo\",\n",
    "        }\n",
    "\n",
    "    # def find_center(self, mask: cv2.Mat):\n",
    "    #     \"\"\"\n",
    "    #     Find the center of the object in the mask\n",
    "\n",
    "    #     Args:\n",
    "    #         mask: binary mask of the object\n",
    "\n",
    "    #     Returns:\n",
    "    #         (cx, cy): center of the object\n",
    "    #     \"\"\"\n",
    "    #     contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #     if contours:\n",
    "    #         largest_contour = max(contours, key=cv2.contourArea)\n",
    "    #         M = cv2.moments(largest_contour)\n",
    "    #         if M[\"m00\"] != 0:\n",
    "    #             cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "    #             cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "    #             return (cx, cy)\n",
    "    #     return None\n",
    "\n",
    "    def find_all_centers(self, mask: cv2.Mat):\n",
    "        \"\"\"\n",
    "        Find all centers of the object in the mask\n",
    "\n",
    "        Args:\n",
    "            mask: binary mask of the object\n",
    "\n",
    "        Returns:\n",
    "            centers: list of centers of the object\n",
    "        \"\"\"\n",
    "\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        centers = []\n",
    "        for contour in contours:\n",
    "            M = cv2.moments(contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "                \n",
    "                # Calculate area and perimeter\n",
    "                area = M[\"m00\"]\n",
    "                perimeter = cv2.arcLength(contour, True)\n",
    "                \n",
    "                # Calculate the aspect ratio of the bounding rectangle\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                if w > h:\n",
    "                    aspect_ratio = float(w) / h\n",
    "                else:\n",
    "                    aspect_ratio = float(h) / w\n",
    "                \n",
    "                # Calculate the extent\n",
    "                rect_area = w * h\n",
    "                extent = float(area) / rect_area\n",
    "                \n",
    "                # Calculate the convex hull area and solidity\n",
    "                hull = cv2.convexHull(contour)\n",
    "                hull_area = cv2.contourArea(hull)\n",
    "                solidity = float(area) / hull_area\n",
    "                \n",
    "                # Filter based on circular properties\n",
    "                if area > 250 :  # Adjust thresholds as needed\n",
    "                    centers.append((cx, cy))\n",
    "        return centers\n",
    "\n",
    "    def bgr_to_hsv(self, frame: cv2.Mat):\n",
    "        \"\"\"converts BGR image to HSV image\"\"\"\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    def create_combined_mask(self, hsv_frame: cv2.Mat, color_ranges):\n",
    "        \"\"\"\n",
    "        Creates a combined mask from multiple color ranges.\n",
    "\n",
    "        Args:\n",
    "            hsv_frame: current frame in HSV.\n",
    "            color_ranges: list or dict of lower and upper HSV bounds.\n",
    "\n",
    "        Returns:\n",
    "            combined_mask: a binary mask combining all ranges.\n",
    "        \"\"\"\n",
    "        combined_mask = None\n",
    "        if isinstance(color_ranges, list):\n",
    "            for color_range in color_ranges:\n",
    "                mask = cv2.inRange(hsv_frame, np.array(color_range[\"lower\"]), np.array(color_range[\"upper\"]))\n",
    "                combined_mask = mask if combined_mask is None else cv2.bitwise_or(combined_mask, mask)\n",
    "        else:\n",
    "            combined_mask = cv2.inRange(hsv_frame, np.array(color_ranges[\"lower\"]), np.array(color_ranges[\"upper\"]))\n",
    "        return combined_mask\n",
    "\n",
    "    def extract_locations(self, frame: cv2.Mat, multi=False, remove_spawn_point=True):\n",
    "        \"\"\"\n",
    "        Extracts the locations of all objects in the frame.\n",
    "\n",
    "        Args:\n",
    "            frame: current frame in BGR.\n",
    "            multi: whether to extract multiple objects of the same type.\n",
    "            remove_spawn_point: whether to remove the spawn point from the frame.\n",
    "\n",
    "        Returns:\n",
    "            positions: dictionary containing the positions of all objects.\n",
    "        \"\"\"\n",
    "        positions = {}\n",
    "        if remove_spawn_point:\n",
    "            frame[220:240, 170:190, :] = 0\n",
    "        hsv = self.bgr_to_hsv(frame)\n",
    "\n",
    "        for name, color_ranges in self.object_colors.items():\n",
    "            combined_mask = self.create_combined_mask(hsv, color_ranges)\n",
    "            center = self.find_all_centers(combined_mask) if multi else self.find_center(combined_mask)\n",
    "            positions[name] = center\n",
    "\n",
    "        return positions\n",
    "\n",
    "    def extract_movement(self, positions: dict, prev_positions: dict):\n",
    "        \"\"\"\n",
    "        Extracts the movement of all objects in the frame\n",
    "\n",
    "        Args:\n",
    "            frame: current frame in BGR\n",
    "            prev_positions: dictionary containing the positions of all objects in the previous frame\n",
    "\n",
    "        Returns:\n",
    "            movements: dictionary containing the movements of all objects\n",
    "        \"\"\"\n",
    "        movements = {}\n",
    "        for name in positions:\n",
    "            if name in prev_positions:\n",
    "                prev_position = prev_positions[name]\n",
    "                if prev_position is not None and positions[name] is not None:\n",
    "                    movements[name] = self.movements[\n",
    "                        np.sign(positions[name][0] - prev_position[0]) * 10\n",
    "                        + np.sign(positions[name][1] - prev_position[1])\n",
    "                    ]\n",
    "                else:\n",
    "                    movements[name] = None\n",
    "            else:\n",
    "                movements[name] = None\n",
    "        return movements\n",
    "\n",
    "    def valid_entity_movements(self, frame: cv2.Mat, entity_center: tuple, offset=20):\n",
    "        \"\"\"\n",
    "        Checks for walls in the immediate vicinity of Pac-Man (up, down, left, right).\n",
    "\n",
    "        Args:\n",
    "            frame: Current frame in BGR\n",
    "            pacman_center: (cx, cy) center of Pac-Man\n",
    "            offset: How many pixels away from the center to check for a wall\n",
    "\n",
    "        Returns:\n",
    "            A dictionary indicating whether pacman can move in each direction.\n",
    "            e.g. {\"up\": True, \"down\": False, \"left\": True, \"right\": False}\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # If we have no detected Pac-Man, just return False in all directions\n",
    "            if entity_center is None:\n",
    "                return {\"up\": False, \"down\": False, \"left\": False, \"right\": False}\n",
    "\n",
    "            hsv = self.bgr_to_hsv(frame)\n",
    "\n",
    "            # Define a rough HSV range for the blue walls (you may need to adjust these)\n",
    "            walls_lower = (100, 100, 100)\n",
    "            walls_upper = (130, 255, 255)\n",
    "\n",
    "            # Create a mask that highlights the walls\n",
    "            walls_mask = cv2.inRange(hsv, walls_lower, walls_upper)\n",
    "\n",
    "            cx, cy = entity_center\n",
    "            height, width = walls_mask.shape\n",
    "\n",
    "            # Safeguard boundaries\n",
    "            up_y = max(cy - offset, 0)\n",
    "            down_y = min(cy + offset, height - 1)\n",
    "            left_x = max(cx - offset, 0)\n",
    "            right_x = min(cx + offset, width - 1)\n",
    "\n",
    "            # Check pixel values in rectangle in each direction\n",
    "\n",
    "            up_wall_matrix = walls_mask[up_y : cy - 10, cx - 10 : cx + 10]\n",
    "            down_wall_matrix = walls_mask[cy + 10 : down_y, cx - 10 : cx + 10]\n",
    "            left_wall_matrix = walls_mask[cy - 10 : cy + 10, left_x : cx - 10]\n",
    "            right_wall_matrix = walls_mask[cy - 10 : cy + 10, cx + 10 : right_x]\n",
    "\n",
    "            up_wall = ~np.any(up_wall_matrix)\n",
    "            down_wall = ~np.any(down_wall_matrix)\n",
    "            left_wall = ~np.any(left_wall_matrix)\n",
    "            right_wall = ~np.any(right_wall_matrix)\n",
    "\n",
    "            return {\n",
    "                \"up\": up_wall,\n",
    "                \"down\": down_wall,\n",
    "                \"left\": left_wall,\n",
    "                \"right\": right_wall,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(entity_center)\n",
    "            return {\"up\": False, \"down\": False, \"left\": False, \"right\": False}\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# 1. Use your existing code (Extract, motion_model, manhattanweights, etc.)\n",
    "################################################################################\n",
    "\n",
    "# For illustration, we assume we have these available:\n",
    "#   class Extract:\n",
    "#       ...\n",
    "#   def manhattanweights(g1, g2, g3, g4, pc):\n",
    "#       ...\n",
    "#   def motion_model(g1, g2, g3, g4, pc, prev_action, allow_motion):\n",
    "#       ...\n",
    "\n",
    "################################################################################\n",
    "# 2. Define a ParticleFilter for Pac-Man\n",
    "################################################################################\n",
    "\n",
    "\n",
    "class ParticleFilter:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_particles,\n",
    "        frame_width,\n",
    "        frame_height,\n",
    "        extract_instance,\n",
    "        spawn_point=(190, 315),\n",
    "        init_prev_action=\"r\",\n",
    "        init_method=\"random\",\n",
    "        resample_method=\"multinomial\",\n",
    "        motion_noise_std=3.0,  # <--- Gaussian noise for motion\n",
    "        measurement_noise_px=2,  # <--- Pixel noise for measurements\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Particle Filter for tracking Pac-Man\n",
    "\n",
    "        Args:\n",
    "            num_particles (int): Number of particles\n",
    "            frame_width (int): Width of the game/maze frame\n",
    "            frame_height (int): Height of the game/maze frame\n",
    "            extract_instance (Extract): An instance of your Extract class\n",
    "            init_prev_action (str): An initial guess for Pac-Man's previous action\n",
    "            init_method (str): Method to initialize particles ('random' or 'center')\n",
    "            motion_noise_std (float): Standard deviation of the Gaussian noise added\n",
    "                                      to each motion step\n",
    "            measurement_noise_px (int): Max random integer offset added to each\n",
    "                                        measured detection location\n",
    "        \"\"\"\n",
    "        self.num_particles = num_particles\n",
    "        self.frame_width = frame_width\n",
    "        self.frame_height = frame_height\n",
    "        self.extract = extract_instance\n",
    "        self.init_prev_action = init_prev_action\n",
    "        self.init_method = init_method\n",
    "        self.spawn_point = spawn_point\n",
    "        self.resample_method = resample_method\n",
    "        self.motion_noise_std = motion_noise_std\n",
    "        self.measurement_noise_px = measurement_noise_px\n",
    "\n",
    "        # Each particle: (x, y, prev_action)\n",
    "        self.entities = [\"pacman\", \"red_ghost\", \"cyan_ghost\", \"pink_ghost\", \"orange_ghost\"]\n",
    "        self.particles = {entity: [] for entity in self.entities}\n",
    "        self.weights = {entity: np.ones(num_particles, dtype=np.float32) / num_particles for entity in self.entities}\n",
    "\n",
    "        for entity in self.entities:\n",
    "            self.initialize_particles(entity)\n",
    "\n",
    "    def initialize_particles(self,entity):\n",
    "        \"\"\"Initialize particles in the valid region of the frame.\"\"\"\n",
    "        self.particles[entity] = []\n",
    "        for _ in range(self.num_particles):\n",
    "            if self.init_method == \"random\":\n",
    "                x = random.randint(0, self.frame_width - 1)\n",
    "                y = random.randint(0, self.frame_height - 1)\n",
    "            elif self.init_method == \"center\":\n",
    "                x = self.frame_width // 2\n",
    "                y = self.frame_height // 2\n",
    "            elif self.init_method == \"spawn_point\" and entity == \"pacman\":\n",
    "                if random.random() < 0.5:\n",
    "                    x = random.randint(\n",
    "                        self.spawn_point[0] - 40, self.spawn_point[0] + 50\n",
    "                    )\n",
    "                    y = random.randint(\n",
    "                        self.spawn_point[1] - 25, self.spawn_point[1] + 25\n",
    "                    )\n",
    "                else:\n",
    "                    x = random.randint(0, self.frame_width - 1)\n",
    "                    y = random.randint(0, self.frame_height - 1)\n",
    "            else:\n",
    "                x = random.randint(0, self.frame_width - 1)\n",
    "                y = random.randint(0, self.frame_height - 1)\n",
    "\n",
    "            self.particles[entity].append((x, y, self.init_prev_action))\n",
    "\n",
    "        self.particles[entity] = np.array(self.particles[entity], dtype=object)\n",
    "    \n",
    "    def delete_ghosts(self,entity):\n",
    "        self.particles[entity] = None\n",
    "\n",
    "\n",
    "    def step(self, frame, prev_frame_positions):\n",
    "        \"\"\"\n",
    "        Main PF step for one iteration.\n",
    "\n",
    "        1) Extract ghost positions from the current frame\n",
    "        2) Determine allowed movements for Pac-Man (walls, etc.)\n",
    "        3) Motion update: apply motion_model to each particle + motion noise\n",
    "        4) Observation update: weigh each particle by how well it matches the detection\n",
    "           (with measurement noise)\n",
    "        5) Resample\n",
    "        6) Estimate the best Pac-Man position from the particles\n",
    "\n",
    "        Args:\n",
    "            frame (np.ndarray): Current game frame (BGR)\n",
    "            prev_frame_positions (dict): Positions from the previous frame\n",
    "                                         (e.g. from extract_locations)\n",
    "\n",
    "        Returns:\n",
    "            best_estimate (tuple): A guess of Pac-Man's position (x, y)\n",
    "        \"\"\"\n",
    "        # 1) Extract ghost positions\n",
    "        # curr_positions = self.extract.extract_locations(\n",
    "        #     frame, multi=False, remove_spawn_point=True\n",
    "        # )\n",
    "\n",
    "        ghost_keys = [\"red_ghost\", \"cyan_ghost\", \"pink_ghost\", \"orange_ghost\"]\n",
    "        # Some ghost positions might be None if not detected\n",
    "        # ghosts = []\n",
    "        # for gkey in ghost_keys:\n",
    "        #     pos = curr_positions.get(gkey, None)\n",
    "        #     if pos is None:\n",
    "        #         self.delete_ghosts(gkey)\n",
    "        #         # If not detected, let's just put something far away\n",
    "        #         ghosts.append((9999, 9999))\n",
    "        #     else:\n",
    "        #         if self.particles[gkey] is None:\n",
    "        #             self.initialize_particles(gkey)\n",
    "        #         ghosts.append(pos)\n",
    "\n",
    "        \n",
    "        # 2) Determine if Pac-Man can move in each direction (allowable moves).\n",
    "        #    For demonstration, we'll get the \"best guess\" of Pac-Man from the last step\n",
    "        #    or from the previous frame positions if available.\n",
    "        if prev_frame_positions and prev_frame_positions.get(\"pacman\") is not None:\n",
    "            # Might be a list of centers or a single center\n",
    "            prev_pacman_pos = prev_frame_positions[\"pacman\"]\n",
    "            if len(prev_pacman_pos) == 0:\n",
    "                px = int(np.mean(self.particles[\"pacman\"][:, 0]))\n",
    "                py = int(np.mean(self.particles[\"pacman\"][:, 1]))\n",
    "                best_guess_pacman = (px, py)\n",
    "            elif isinstance(prev_pacman_pos, list) and len(prev_pacman_pos) > 0:\n",
    "                best_guess_pacman = prev_pacman_pos[0]\n",
    "            else:\n",
    "                best_guess_pacman = prev_pacman_pos\n",
    "        else:\n",
    "            # If no info, just pick the average of the current particles\n",
    "            px = int(np.mean(self.particles[\"pacman\"][:, 0]))\n",
    "            py = int(np.mean(self.particles[\"pacman\"][:, 1]))\n",
    "            best_guess_pacman = (px, py)\n",
    "        ghostspos = {}\n",
    "        for gkey in ghost_keys:\n",
    "            if prev_frame_positions and prev_frame_positions.get(gkey) is not None and self.particles[gkey] is not None:\n",
    "                # Might be a list of centers or a single center\n",
    "                prev_ghost_pos = prev_frame_positions[gkey]\n",
    "                if prev_ghost_pos is not None and isinstance(prev_ghost_pos, list) and len(prev_ghost_pos) > 0:\n",
    "                    bestgpos = prev_ghost_pos[0]\n",
    "                else:\n",
    "                    bestgpos = prev_ghost_pos\n",
    "            else:\n",
    "                # If no info, just pick the average of the current particles\n",
    "                if self.particles[gkey] is not None:\n",
    "                    px = int(np.mean(self.particles[gkey][:, 0]))\n",
    "                    py = int(np.mean(self.particles[gkey][:, 1]))\n",
    "                    bestgpos = (px, py)\n",
    "                else:\n",
    "                    bestgpos = None\n",
    "                    \n",
    "            ghostspos[gkey] = bestgpos\n",
    "\n",
    "\n",
    "        allow_dict = self._compute_allow_dict(frame, best_guess_pacman)\n",
    "        ghostallow = {}\n",
    "        for gkey in ghost_keys:\n",
    "            if self.particles[gkey] is not None:\n",
    "                ghostallow[gkey] = self._compute_allow_dict(frame, ghostspos[gkey])\n",
    "            \n",
    "        ghosts = []\n",
    "        for gkey in ghost_keys:\n",
    "            if self.particles[gkey] is None:\n",
    "                # If not detected, let's just put something far away\n",
    "                ghosts.append((9999, 9999))\n",
    "            else:\n",
    "                ghosts.append(ghostspos[gkey])\n",
    "        # 3) Motion update\n",
    "        self._motion_update(ghosts, allow_dict)\n",
    "        for gkey in ghost_keys:\n",
    "            if self.particles[gkey] is not None:\n",
    "                self.ghost_motion(gkey,best_guess_pacman,ghostallow[gkey])\n",
    "\n",
    "        # 4) Observation update\n",
    "        positions = {}\n",
    "        for entity in self.entities:\n",
    "            positions[entity] = self._observation_update(frame,entity)\n",
    "            if positions[entity] is None:\n",
    "                print(\"Entity \",entity,\" None \")\n",
    "            if entity in ghost_keys:\n",
    "                if positions[entity] is None:\n",
    "                    self.delete_ghosts(entity)\n",
    "                else:\n",
    "                    if self.particles[entity] is None:\n",
    "                        self.initialize_particles(entity)\n",
    "\n",
    "        # 5) Resample\n",
    "        for entity in self.entities:\n",
    "            if self.particles[entity] is not None:\n",
    "                self._resample(entity,method=self.resample_method)\n",
    "\n",
    "        # 6) Estimate\n",
    "\n",
    "        best_estimate = {}\n",
    "        for entity in self.entities:\n",
    "            if self.particles[entity] is not None:\n",
    "                best_estimate[entity] = self.estimate(entity)\n",
    "            else:\n",
    "                best_estimate[entity] = None\n",
    "        return best_estimate, positions\n",
    "\n",
    "    def ghost_motion(self,ghost,pc,allow_motion_dict):\n",
    "        \n",
    "        updated_particles = []\n",
    "        for i, (x, y, prev_act) in enumerate(self.particles[ghost]):\n",
    "            ghostposition = (x, y)\n",
    "            # motion_model returns p_left, p_right, p_up, p_down\n",
    "            p_l, p_r, p_u, p_d = motion_model_ghosts(\n",
    "                ghostposition,pc,allow_motion_dict\n",
    "            )\n",
    "\n",
    "            # Normalize if necessary\n",
    "            probs = np.array([p_l, p_r, p_u, p_d])\n",
    "            probs_sum = probs.sum()\n",
    "            if probs_sum > 0:\n",
    "                probs /= probs_sum\n",
    "            else:\n",
    "                # fallback: uniform\n",
    "                probs = np.ones(4) / 4.0\n",
    "            action = np.random.choice([\"l\", \"r\", \"u\", \"d\"], p=probs)\n",
    "\n",
    "            # Move the particle\n",
    "            new_x, new_y = x, y\n",
    "            if action == \"l\":\n",
    "                new_x = x - 2\n",
    "            elif action == \"r\":\n",
    "                new_x = x + 2\n",
    "            elif action == \"u\":\n",
    "                new_y = y - 2\n",
    "            elif action == \"d\":\n",
    "                new_y = y + 2\n",
    "\n",
    "            # Clamp bounds\n",
    "            new_x = max(0, min(self.frame_width - 1, new_x))\n",
    "            new_y = max(0, min(self.frame_height - 1, new_y))\n",
    "            # new_x = new_x % self.frame_width\n",
    "            # new_y = new_y % self.frame_height\n",
    "\n",
    "            # Add motion noise (Gaussian).\n",
    "            # We'll clamp again in case noise pushes it out of bounds.\n",
    "            noise_dx = int(round(random.gauss(0, self.motion_noise_std)))\n",
    "            noise_dy = int(round(random.gauss(0, self.motion_noise_std)))\n",
    "            new_x = max(0, min(self.frame_width - 1, new_x + noise_dx))\n",
    "            new_y = max(0, min(self.frame_height - 1, new_y + noise_dy))\n",
    "\n",
    "            # new_x = (new_x + noise_dx) % self.frame_width\n",
    "            # new_y = (new_y + noise_dy) % self.frame_height\n",
    "\n",
    "            updated_particles.append((new_x, new_y, action))\n",
    "\n",
    "        self.particles[ghost] = np.array(updated_particles, dtype=object)\n",
    "        \n",
    "    def _motion_update(self, ghosts, allow_motion_dict):\n",
    "        \"\"\"\n",
    "        Moves each particle according to your 'motion_model'. We:\n",
    "          - Extract the probabilities from motion_model(...)\n",
    "          - Sample an action\n",
    "          - Update particle state\n",
    "          - Add random motion noise to x and/or y\n",
    "        \"\"\"\n",
    "        updated_particles = []\n",
    "        for i, (x, y, prev_act) in enumerate(self.particles[\"pacman\"]):\n",
    "            pc = (x, y)\n",
    "            g1, g2, g3, g4 = ghosts\n",
    "            # motion_model returns p_left, p_right, p_up, p_down\n",
    "            p_l, p_r, p_u, p_d = motion_model(\n",
    "                g1, g2, g3, g4, pc, prev_act, allow_motion_dict\n",
    "            )\n",
    "\n",
    "            # Normalize if necessary\n",
    "            probs = np.array([p_l, p_r, p_u, p_d])\n",
    "            probs_sum = probs.sum()\n",
    "            if probs_sum > 0:\n",
    "                probs /= probs_sum\n",
    "            else:\n",
    "                # fallback: uniform\n",
    "                probs = np.ones(4) / 4.0\n",
    "\n",
    "            action = np.random.choice([\"l\", \"r\", \"u\", \"d\"], p=probs)\n",
    "\n",
    "            # Move the particle\n",
    "            new_x, new_y = x, y\n",
    "            if action == \"l\":\n",
    "                new_x = x - 2\n",
    "            elif action == \"r\":\n",
    "                new_x = x + 2\n",
    "            elif action == \"u\":\n",
    "                new_y = y - 2\n",
    "            elif action == \"d\":\n",
    "                new_y = y + 2\n",
    "\n",
    "            # Clamp bounds\n",
    "            new_x = max(0, min(self.frame_width - 1, new_x))\n",
    "            new_y = max(0, min(self.frame_height - 1, new_y))\n",
    "            # new_x = new_x % self.frame_width\n",
    "            # new_y = new_y % self.frame_height\n",
    "\n",
    "            # Add motion noise (Gaussian).\n",
    "            # We'll clamp again in case noise pushes it out of bounds.\n",
    "            noise_dx = int(round(random.gauss(0, self.motion_noise_std)))\n",
    "            noise_dy = int(round(random.gauss(0, self.motion_noise_std)))\n",
    "            new_x = max(0, min(self.frame_width - 1, new_x + noise_dx))\n",
    "            new_y = max(0, min(self.frame_height - 1, new_y + noise_dy))\n",
    "\n",
    "            # new_x = (new_x + noise_dx) % self.frame_width\n",
    "            # new_y = (new_y + noise_dy) % self.frame_height\n",
    "\n",
    "            updated_particles.append((new_x, new_y, action))\n",
    "\n",
    "        self.particles[\"pacman\"] = np.array(updated_particles, dtype=object)\n",
    "\n",
    "    def _observation_update(self, frame,entity):\n",
    "        \"\"\"\n",
    "        Weigh each particle by how well it matches the detected positions of Pac-Man.\n",
    "        If multiple centers are found, we split probability among them.\n",
    "\n",
    "        Adds measurement noise by artificially jittering the positions we get from\n",
    "        extract_locations. This simulates uncertain detection.\n",
    "        \"\"\"\n",
    "        positions = self.extract.extract_locations(\n",
    "            frame, multi=True, remove_spawn_point=False\n",
    "        )\n",
    "        entity_centers = positions[entity]\n",
    "\n",
    "        # If no detection, you might want to reduce weights or keep them as is\n",
    "        if not entity_centers:\n",
    "            self.weights[entity] *= 0.8\n",
    "            return\n",
    "        \n",
    "        if self.particles[entity] is None:\n",
    "            self.weights[entity] *= 0.8\n",
    "            return positions[entity]\n",
    "\n",
    "        # Inject measurement noise into each detected center\n",
    "        noisy_centers = []\n",
    "        for c in entity_centers:\n",
    "            # small random offset in x and y\n",
    "            # Â± self.measurement_noise_px\n",
    "            nx = c[0] + random.randint(\n",
    "                -self.measurement_noise_px, self.measurement_noise_px\n",
    "            )\n",
    "            ny = c[1] + random.randint(\n",
    "                -self.measurement_noise_px, self.measurement_noise_px\n",
    "            )\n",
    "            # clamp\n",
    "            nx = max(0, min(self.frame_width - 1, nx))\n",
    "            ny = max(0, min(self.frame_height - 1, ny))\n",
    "            noisy_centers.append((nx, ny))\n",
    "\n",
    "        match_threshold = 15\n",
    "        num_centers = len(noisy_centers)\n",
    "        center_prob = 1.0 / num_centers\n",
    "\n",
    "        for i, (x, y, _) in enumerate(self.particles[entity]):\n",
    "            # Find distance to the closest noisy center\n",
    "            min_dist = float(\"inf\")\n",
    "            for c in noisy_centers:\n",
    "                dist = np.hypot(x - c[0], y - c[1])\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "\n",
    "            if min_dist < match_threshold:\n",
    "                # The closer, the higher the weighting. Example: 1 + fraction * (match_threshold - dist)/match_threshold\n",
    "                self.weights[entity][i] *= (\n",
    "                    1.0 + center_prob * (match_threshold - min_dist) / match_threshold\n",
    "                )\n",
    "            else:\n",
    "                # If too far from all detections, weight is reduced\n",
    "                self.weights[entity][i] *= 0.5\n",
    "\n",
    "        # Normalize weights\n",
    "        weight_sum = np.sum(self.weights[entity])\n",
    "        if weight_sum > 0:\n",
    "            self.weights[entity] /= weight_sum\n",
    "        else:\n",
    "            self.weights[entity][:] = 1.0 / len(self.weights[entity])\n",
    "\n",
    "        return positions[entity]\n",
    "\n",
    "    def _resample(self, entity,method=\"multinomial\"):\n",
    "        \"\"\"\n",
    "        Systematic or multinomial resampling of the particles\n",
    "        based on current weights.\n",
    "        \"\"\"\n",
    "        N = self.num_particles\n",
    "        new_particles = []\n",
    "        # normalized weights\n",
    "        self.weights[entity] = self.weights[entity] / np.sum(self.weights[entity])\n",
    "\n",
    "        if method == \"multinomial\":\n",
    "            indices = np.random.choice(range(N), size=N, p=self.weights[entity])\n",
    "            for idx in indices:\n",
    "                new_particles.append(self.particles[entity][idx])\n",
    "\n",
    "            self.particles[entity] = np.array(new_particles, dtype=object)\n",
    "            self.weights[entity] = np.ones(N, dtype=np.float32) / N\n",
    "        elif method == \"systematic\":\n",
    "            indices = np.zeros(N, dtype=int)\n",
    "            r = np.random.rand() / N\n",
    "            c = self.weights[entity][0]\n",
    "            i = 0\n",
    "            for m in range(N - 1):\n",
    "                U = r + m / N\n",
    "                while U > c:\n",
    "                    i += 1\n",
    "                    c += self.weights[entity][i]\n",
    "                indices[m] = i\n",
    "\n",
    "            for idx in indices:\n",
    "                new_particles.append(self.particles[entity][idx])\n",
    "\n",
    "            self.particles[entity] = np.array(new_particles, dtype=object)\n",
    "            self.weights[entity] = np.ones(N, dtype=np.float32) / N\n",
    "\n",
    "    def estimate(self,entity):\n",
    "        \"\"\"\n",
    "        Estimate Pac-Man's position from the particles (e.g. weighted mean).\n",
    "        Returns:\n",
    "            (est_x, est_y)\n",
    "        \"\"\"\n",
    "        if self.weights[entity].sum() < 1e-7:\n",
    "            # Fallback\n",
    "            est_x = int(np.mean(self.particles[entity][:, 0]))\n",
    "            est_y = int(np.mean(self.particles[entity][:, 1]))\n",
    "            return (est_x, est_y)\n",
    "\n",
    "        # Weighted average\n",
    "        w_norm = self.weights[entity] / self.weights[entity].sum()\n",
    "        est_x = int(np.sum(self.particles[entity][:, 0] * w_norm))\n",
    "        est_y = int(np.sum(self.particles[entity][:, 1] * w_norm))\n",
    "        return (est_x, est_y)\n",
    "\n",
    "    def _compute_allow_dict(self, frame, entity_center):\n",
    "        \"\"\"\n",
    "        Use your valid_pacman_movements(...) (slightly modified) to get a dictionary:\n",
    "          {'u': 1/0, 'd': 1/0, 'l': 1/0, 'r': 1/0}\n",
    "        \"\"\"\n",
    "        valid_moves = self.extract.valid_entity_movements(frame, entity_center)\n",
    "        allow_dict = {\n",
    "            \"u\": 1 if valid_moves[\"up\"] else 0,\n",
    "            \"d\": 1 if valid_moves[\"down\"] else 0,\n",
    "            \"l\": 1 if valid_moves[\"left\"] else 0,\n",
    "            \"r\": 1 if valid_moves[\"right\"] else 0,\n",
    "        }\n",
    "        return allow_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_loop():\n",
    "    # Instantiate your Extract\n",
    "    extract = Extract()  # from your code\n",
    "\n",
    "    # Example: open a webcam or video\n",
    "    cap = cv2.VideoCapture(\"pacmanvid.mp4\")\n",
    "\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    video_filename = \"random_init.avi\"  # Output video file name\n",
    "    frame_width, frame_height = frame_width, frame_height  # Frame size\n",
    "    fps = 10  # Frames per second\n",
    "    fps = 30  # Frames per second\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")  # Codec\n",
    "    out = cv2.VideoWriter(video_filename, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    # Create the PF, now with noise parameters\n",
    "    pf = ParticleFilter(\n",
    "        num_particles=500,\n",
    "        frame_width=frame_width,\n",
    "        frame_height=frame_height,\n",
    "        extract_instance=extract,\n",
    "        init_prev_action=\"r\",\n",
    "        init_method=\"random\",\n",
    "        resample_method=\"multinomial\",\n",
    "        motion_noise_std=4,  # tweak to suit your environment\n",
    "        measurement_noise_px=3,  # tweak to suit your environment\n",
    "    )\n",
    "\n",
    "\n",
    "    # Define colors for each entity\n",
    "    colors = {\n",
    "        \"pacman\": (0, 255, 255),       # Yellow\n",
    "        \"red_ghost\": (0, 0, 255),      # Red\n",
    "        \"cyan_ghost\": (255, 255, 0),   # Cyan\n",
    "        \"pink_ghost\": (255, 0, 0),   # Pink\n",
    "        \"orange_ghost\": (0, 165, 255)  # Orange\n",
    "    }\n",
    "\n",
    "    prev_positions = None\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        best_estimates, positions = pf.step(frame, prev_positions)\n",
    "\n",
    "        # For debug: draw particles for each entity\n",
    "        for entity in pf.entities:\n",
    "            if best_estimates[entity] is not None:\n",
    "                entity_particles = pf.particles[entity]\n",
    "                for x, y, _ in entity_particles:\n",
    "                    cv2.circle(frame, (x, y), 1, colors[entity], -1)\n",
    "\n",
    "                # Draw the best estimate in a larger circle\n",
    "                best_estimate = best_estimates[entity]\n",
    "                cv2.circle(frame, best_estimate, 5, colors[entity], -1)\n",
    "\n",
    "                if positions and positions.get(entity, None):\n",
    "                    if isinstance(positions[entity], list):\n",
    "                        for c in positions[entity]:\n",
    "                            cv2.circle(frame, c, 5, colors[entity], 2)\n",
    "                    elif positions[entity] is not None:\n",
    "                        cv2.circle(frame, positions[entity], 5, colors[entity], 2)\n",
    "\n",
    "        # Update prev_positions for next iteration if needed\n",
    "        prev_positions = positions\n",
    "\n",
    "        cv2.imshow(\"Pacman Tracking PF (with noise)\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break  # Esc to quit\n",
    "        # print(\"Best Estimate Locations:\")\n",
    "        # for entity in pf.entities:\n",
    "        #     print(f\"{entity.capitalize()}: {best_estimates[entity]}\")\n",
    "        #     if positions and positions.get(entity, None):\n",
    "        #         print(f\"Detected {entity.capitalize()} Locations: {positions[entity]}\")\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    out.release()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity  cyan_ghost  None \n",
      "Entity  cyan_ghost  None \n",
      "Entity  cyan_ghost  None \n",
      "Entity  cyan_ghost  None \n",
      "Entity  cyan_ghost  None \n",
      "Entity  cyan_ghost  None \n",
      "Entity  cyan_ghost  None \n",
      "Entity  cyan_ghost  None \n",
      "Entity  cyan_ghost  None \n",
      "Entity  cyan_ghost  None \n",
      "Entity  cyan_ghost  None \n",
      "Entity  cyan_ghost  None \n",
      "Entity  cyan_ghost  None \n",
      "Entity  cyan_ghost  None \n",
      "Entity  cyan_ghost  None \n"
     ]
    }
   ],
   "source": [
    "main_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract = Extract()  # from your code\n",
    "\n",
    "# Example: open a webcam or video\n",
    "cap = cv2.VideoCapture(\"4m.mp4\")\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Create the PF, now with noise parameters\n",
    "pf = ParticleFilter(\n",
    "    num_particles=2000,\n",
    "    frame_width=frame_width,\n",
    "    frame_height=frame_height,\n",
    "    extract_instance=extract,\n",
    "    init_prev_action=\"r\",\n",
    "    init_method=\"spawn_point\",\n",
    "    motion_noise_std=2,  # tweak to suit your environment\n",
    "    measurement_noise_px=3,  # tweak to suit your environment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"4m.mp4\")\n",
    "frame_count = 0\n",
    "frames = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame_count += 1\n",
    "    frames.append(frame)\n",
    "    if frame_count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_iter = iter(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = {\"pacman\": pf.spawn_point}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'circle'\n> Overload resolution failed:\n>  - Can't parse 'center'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'center'. Sequence item with index 0 has a wrong type\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[184], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m positions \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mextract_locations(frame, multi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, remove_spawn_point\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m particle \u001b[38;5;129;01min\u001b[39;00m pf\u001b[38;5;241m.\u001b[39mparticles:\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcircle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mparticle\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparticle\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m cv2\u001b[38;5;241m.\u001b[39mcircle(frame, best_estimate, \u001b[38;5;241m10\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPacman Tracking PF (with noise)\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'circle'\n> Overload resolution failed:\n>  - Can't parse 'center'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'center'. Sequence item with index 0 has a wrong type\n"
     ]
    }
   ],
   "source": [
    "frame = next(frame_iter)\n",
    "best_estimate = pf.step(frame, prev_frame_positions=positions)\n",
    "positions = extract.extract_locations(frame, multi=True, remove_spawn_point=False)\n",
    "for particle in pf.particles:\n",
    "    cv2.circle(frame, (particle[0], particle[1]), 1, (0, 255, 0), -1)\n",
    "cv2.circle(frame, best_estimate, 10, (0, 0, 255), -1)\n",
    "cv2.imshow(\"Pacman Tracking PF (with noise)\", frame)\n",
    "while True:\n",
    "    k = cv2.waitKey(0)\n",
    "    if k == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pacman': [(190, 315),\n",
       "  (188, 240),\n",
       "  (179, 240),\n",
       "  (224, 233),\n",
       "  (210, 235),\n",
       "  (197, 236),\n",
       "  (168, 236),\n",
       "  (156, 236)],\n",
       " 'red_ghost': [(196, 166),\n",
       "  (182, 166),\n",
       "  (189, 164),\n",
       "  (178, 162),\n",
       "  (182, 161),\n",
       "  (196, 153)],\n",
       " 'cyan_ghost': [(162, 198)],\n",
       " 'pink_ghost': [(279, 369),\n",
       "  (189, 344),\n",
       "  (99, 369),\n",
       "  (315, 310),\n",
       "  (249, 296),\n",
       "  (129, 296),\n",
       "  (63, 310),\n",
       "  (189, 264),\n",
       "  (269, 236),\n",
       "  (109, 236),\n",
       "  (217, 335),\n",
       "  (221, 189),\n",
       "  (210, 188),\n",
       "  (188, 198),\n",
       "  (156, 188),\n",
       "  (188, 185),\n",
       "  (190, 196),\n",
       "  (191, 155),\n",
       "  (181, 155),\n",
       "  (262, 137),\n",
       "  (322, 96),\n",
       "  (189, 104),\n",
       "  (116, 136),\n",
       "  (56, 97),\n",
       "  (322, 50),\n",
       "  (249, 50),\n",
       "  (129, 49),\n",
       "  (56, 50),\n",
       "  (195, 62)],\n",
       " 'orange_ghost': [(216, 200),\n",
       "  (216, 186),\n",
       "  (196, 166),\n",
       "  (182, 166),\n",
       "  (189, 164),\n",
       "  (178, 162),\n",
       "  (182, 161),\n",
       "  (196, 153)]}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = next(frame_iter)\n",
    "best_estimate = pf.step(frame, prev_frame_positions=positions)\n",
    "positions = extract.extract_locations(frame, multi=True, remove_spawn_point=True)\n",
    "for particle in pf.particles:\n",
    "    cv2.circle(frame, (particle[0], particle[1]), 1, (0, 255, 0), -1)\n",
    "cv2.circle(frame, best_estimate, 10, (0, 0, 255), -1)\n",
    "cv2.imshow(\"Pacman Tracking PF (with noise) step 2\", frame)\n",
    "\n",
    "while True:\n",
    "    k = cv2.waitKey(0)\n",
    "    if k == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"4m.mp4\")\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract = Extract()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Extract the positions of all objects in the frame\n",
    "    positions = extract.extract_locations(frame, multi=False, remove_spawn_point=False)\n",
    "\n",
    "    # for name, value in positions.items():\n",
    "    #     if value is not None:\n",
    "    #         cv2.circle(frame, value, 5, extract.ghost_marker_colors[name], 10)\n",
    "    cv2.circle(\n",
    "        frame, positions[\"pacman\"], 20, extract.ghost_marker_colors[\"pacman\"], -1\n",
    "    )\n",
    "\n",
    "    cv2.imshow(\"Object Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000\n",
    "new_particles = []\n",
    "\n",
    "# random particles\n",
    "particles = np.random.randint(0, 300, (N, 2))\n",
    "# random weights\n",
    "weights = np.random.rand(N)\n",
    "\n",
    "weights = weights / np.sum(weights)\n",
    "indices = np.random.choice(range(N), size=N, p=weights)\n",
    "for idx in indices:\n",
    "    new_particles.append(particles[idx])\n",
    "\n",
    "particles = np.array(new_particles, dtype=object)\n",
    "weights = np.ones(N, dtype=np.float32) / N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
